---
layout: default
permalink: /
---

Hello!

My name is Alex Paino and I am a machine learning engineer at [Sift Science](http://www.siftscience.com), where I focus on building [the most accurate models possible](https://engineering.siftscience.com/large-scale-decision-forests-lessons-learned/) in support of our various abuse prevention products. 
Prior to joining Sift, I graduated from the University of Missouri in 2014, where I studied Computer Engineering and Mathematics and conducted [research](/research) applying Evolutionary Computation and Computer Vision techniques to explosive hazard detection. 


Projects
-----------
[**Deep Text Corrector**](https://github.com/atpaino/deep-text-corrector)

Uses sequence-to-sequence models to automatically correct simple errors in conversational written English. 
The latest results of the project (as described in [this post](/2017/01/03/deep-text-correcter.html)) show that it significantly outperforms an identity function baseline. 
Code is available on GitHub along with a more thorough description [here](https://github.com/atpaino/deep-text-corrector).

Articles
-----------

[**ML Experiments at Sift Science, Pt. 3: Building the Right Tools**](https://engineering.siftscience.com/ml-experiments-pt-3-tooling/)

*January 2017, Sift Science Blog*

The finale of this series, this post discusses tools we have built that make it easy to correctly conduct and analyze experiments, with an emphasis on improving the productivity of the larger engineering organization.

[**ML Experiments at Sift Science, Part 2: Analyzing Thousands of Models**](https://engineering.siftscience.com/ml-experiments-pt-2-analyzing-thousands-of-models/)

*December 2016, Sift Science Blog*

The second in a three-part series on ML experimentation at Sift Science, this post describes how we efficiently and effectively analyze the results of ML experiments involving several thousand models.

[**ML Experiments at Sift Science, Part 1: Minimizing Bias**](https://engineering.siftscience.com/ml-experiments-part-1-minimizing-bias/)

*December 2016, Sift Science Blog*

The first in a three-part series on ML experimentation at Sift Science, this post details how we minimize bias in offline experiments.

[**Large Scale Decision Forests: Lessons Learned**](https://engineering.siftscience.com/large-scale-decision-forests-lessons-learned/)

*August 2015, Sift Science Blog*

A write-up of 7 lessons learned during our project to implement and deploy an in-house random forest model. 

Talks
-----------
[**Turn Up the Bayes, Part 2**](https://engineering.siftscience.com/turn-up-the-bayes-part-2/)

*August 2015, Sift Science*

I gave a tech talk on the same subject discussed in [Large Scale Decision Forests: Lessons Learned](https://engineering.siftscience.com/large-scale-decision-forests-lessons-learned/).


Publications
-----------
2014: **[A method of evolving novel feature extraction algorithms for detecting buried objects in FLIR imagery using genetic programming](http://spie.org/Publications/Proceedings/Paper/10.1117/12.2049950)**
*Authors: Paino, Alex; Keller, James; Popescu, Mihail; Stone, Kevin*

2013: **[Using evolutionary computation to optimize an SVM used in detecting buried objects in FLIR imagery](http://dx.doi.org/10.1117/12.2014774)**
*Authors: Paino, Alex; Popescu, Mihail; Keller, James; Stone, Kevin*

2012: **[Detection of buried objects in FLIR imaging using mathematical morphology and SVM](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6291520&isnumber=6291498)**
*Authors: Popescu, Mihail; Paino, Alex; Stone, Kevin; Keller, James*
